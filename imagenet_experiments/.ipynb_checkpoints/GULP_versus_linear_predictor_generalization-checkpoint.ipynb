{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from itertools import product\n",
    "import math\n",
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from scipy.cluster.hierarchy import dendrogram, leaves_list\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.manifold import TSNE, MDS\n",
    "# import umap\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import time\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../\"))\n",
    "\n",
    "from distance_functions import *\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load distances and representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"distances/train/pretrained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ImageNet distances between train datasets\n",
    "filenames = os.listdir(folder)\n",
    "distnames = []\n",
    "for filename in filenames:\n",
    "    if filename.endswith(\"npy\"):\n",
    "        distnames.append(filename[:-4])\n",
    "distnames = np.sort(distnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lin_cka_dist' 'lin_cka_prime_dist' 'mean_cca_e2e' 'mean_sq_cca_e2e'\n",
      " 'predictor_dist_0.0' 'predictor_dist_0.0001' 'predictor_dist_0.001'\n",
      " 'predictor_dist_0.01' 'predictor_dist_0.1' 'predictor_dist_1.0'\n",
      " 'predictor_dist_10.0' 'predictor_dist_100.0' 'predictor_dist_1000.0'\n",
      " 'predictor_dist_10000.0' 'predictor_dist_1e-05' 'predictor_dist_1e-06'\n",
      " 'predictor_dist_1e-07' 'predictor_dist_1e-08' 'predictor_dist_1e-09'\n",
      " 'predictor_dist_1e-10' 'predictor_dist_1e-11' 'predictor_dist_1e-12'\n",
      " 'predictor_dist_1e-13' 'predictor_dist_1e-14' 'predictor_dist_1e-15'\n",
      " 'predictor_dist_1e-16' 'predictor_dist_1e-17' 'predictor_dist_1e-18'\n",
      " 'predictor_dist_1e-19' 'predictor_dist_1e-20' 'procrustes'\n",
      " 'pwcca_dist_e2e']\n"
     ]
    }
   ],
   "source": [
    "print(distnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = np.load(f\"{folder}/stats.npz\")\n",
    "model_names = stats[\"model_names\"]\n",
    "total_models = len(model_names)\n",
    "dist_pairs_saved = stats[\"dist_pairs_saved\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Check all distance pairs are saved. The output should be all-zeros\n",
    "print(np.arange(total_models) - np.sum(dist_pairs_saved, axis=0))\n",
    "print(np.arange(total_models) - np.flip(np.sum(dist_pairs_saved, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alexnet_pretrained_rep' 'convnext_base_pretrained_rep'\n",
      " 'convnext_large_pretrained_rep' 'convnext_small_pretrained_rep'\n",
      " 'convnext_tiny_pretrained_rep' 'efficientnet_b0_pretrained_rep'\n",
      " 'efficientnet_b1_pretrained_rep' 'efficientnet_b2_pretrained_rep'\n",
      " 'efficientnet_b3_pretrained_rep' 'efficientnet_b4_pretrained_rep'\n",
      " 'efficientnet_b5_pretrained_rep' 'efficientnet_b6_pretrained_rep'\n",
      " 'efficientnet_b7_pretrained_rep' 'googlenet_pretrained_rep'\n",
      " 'inception_pretrained_rep' 'mnasnet_pretrained_rep'\n",
      " 'mobilenet_v2_pretrained_rep' 'mobilenet_v3_large_pretrained_rep'\n",
      " 'mobilenet_v3_small_pretrained_rep' 'regnet_x_16gf_pretrained_rep'\n",
      " 'regnet_x_1_6gf_pretrained_rep' 'regnet_x_32gf_pretrained_rep'\n",
      " 'regnet_x_3_2gf_pretrained_rep' 'regnet_x_400mf_pretrained_rep'\n",
      " 'regnet_x_800mf_pretrained_rep' 'regnet_x_8gf_pretrained_rep'\n",
      " 'regnet_y_16gf_pretrained_rep' 'regnet_y_1_6gf_pretrained_rep'\n",
      " 'regnet_y_32gf_pretrained_rep' 'regnet_y_3_2gf_pretrained_rep'\n",
      " 'regnet_y_400mf_pretrained_rep' 'regnet_y_800mf_pretrained_rep'\n",
      " 'regnet_y_8gf_pretrained_rep' 'resnet18_pretrained_rep'\n",
      " 'resnext50_32x4d_pretrained_rep' 'vgg16_pretrained_rep'\n",
      " 'wide_resnet50_2_pretrained_rep']\n"
     ]
    }
   ],
   "source": [
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_cka_dist\n",
      "lin_cka_prime_dist\n",
      "mean_cca_e2e\n",
      "mean_sq_cca_e2e\n",
      "predictor_dist_0.0\n",
      "predictor_dist_0.0001\n",
      "predictor_dist_0.001\n",
      "predictor_dist_0.01\n",
      "predictor_dist_0.1\n",
      "predictor_dist_1.0\n",
      "predictor_dist_10.0\n",
      "predictor_dist_100.0\n",
      "predictor_dist_1000.0\n",
      "predictor_dist_10000.0\n",
      "predictor_dist_1e-05\n",
      "predictor_dist_1e-06\n",
      "predictor_dist_1e-07\n",
      "predictor_dist_1e-08\n",
      "predictor_dist_1e-09\n",
      "predictor_dist_1e-10\n",
      "predictor_dist_1e-11\n",
      "predictor_dist_1e-12\n",
      "predictor_dist_1e-13\n",
      "predictor_dist_1e-14\n",
      "predictor_dist_1e-15\n",
      "predictor_dist_1e-16\n",
      "predictor_dist_1e-17\n",
      "predictor_dist_1e-18\n",
      "predictor_dist_1e-19\n",
      "predictor_dist_1e-20\n",
      "procrustes\n",
      "pwcca_dist_e2e\n"
     ]
    }
   ],
   "source": [
    "distances = {}\n",
    "def symmetrize(A):\n",
    "    n = A.shape[0]\n",
    "    B = A.copy()\n",
    "    B[np.tril_indices(n)] = B.T[np.tril_indices(n)]\n",
    "    return B\n",
    "for distname in distnames:\n",
    "    print(distname)\n",
    "    curr_dist = np.load(f\"{folder}/{distname}.npy\")  \n",
    "    distances[distname] = symmetrize(curr_dist)\n",
    "#     print(distances[distname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet_pretrained_rep\n",
      "convnext_base_pretrained_rep\n",
      "convnext_large_pretrained_rep\n",
      "convnext_small_pretrained_rep\n",
      "convnext_tiny_pretrained_rep\n",
      "efficientnet_b0_pretrained_rep\n",
      "efficientnet_b1_pretrained_rep\n",
      "efficientnet_b2_pretrained_rep\n",
      "efficientnet_b3_pretrained_rep\n",
      "efficientnet_b4_pretrained_rep\n",
      "efficientnet_b5_pretrained_rep\n",
      "efficientnet_b6_pretrained_rep\n",
      "efficientnet_b7_pretrained_rep\n",
      "googlenet_pretrained_rep\n",
      "inception_pretrained_rep\n",
      "mnasnet_pretrained_rep\n",
      "mobilenet_v2_pretrained_rep\n",
      "mobilenet_v3_large_pretrained_rep\n",
      "mobilenet_v3_small_pretrained_rep\n",
      "regnet_x_16gf_pretrained_rep\n",
      "regnet_x_1_6gf_pretrained_rep\n",
      "regnet_x_32gf_pretrained_rep\n",
      "regnet_x_3_2gf_pretrained_rep\n",
      "regnet_x_400mf_pretrained_rep\n",
      "regnet_x_800mf_pretrained_rep\n",
      "regnet_x_8gf_pretrained_rep\n",
      "regnet_y_16gf_pretrained_rep\n",
      "regnet_y_1_6gf_pretrained_rep\n",
      "regnet_y_32gf_pretrained_rep\n",
      "regnet_y_3_2gf_pretrained_rep\n",
      "regnet_y_400mf_pretrained_rep\n",
      "regnet_y_800mf_pretrained_rep\n",
      "regnet_y_8gf_pretrained_rep\n",
      "resnet18_pretrained_rep\n",
      "resnext50_32x4d_pretrained_rep\n",
      "vgg16_pretrained_rep\n",
      "wide_resnet50_2_pretrained_rep\n"
     ]
    }
   ],
   "source": [
    "rep_folder_prefix = '../../imagenet_experiments/'\n",
    "train_reps_folder = rep_folder_prefix + 'reps/train/10000_eval/'\n",
    "val_reps_folder = rep_folder_prefix + 'reps/val/3000_eval/'\n",
    "\n",
    "# Load ImageNet representations\n",
    "reps_train = {} # Train dataset\n",
    "reps_val = {} # Validation dataset\n",
    "try:\n",
    "    for model_name in model_names:\n",
    "        print(model_name)\n",
    "        rep1 = np.load(train_reps_folder + model_name + \".npy\")\n",
    "        # center and normalize\n",
    "        rep1 = rep1 - rep1.mean(axis=1, keepdims=True)\n",
    "        rep1 = rep1 / np.linalg.norm(rep1)\n",
    "        rep1 = rep1 * np.sqrt(rep1.shape[1])\n",
    "        reps_train[model_name] = rep1\n",
    "\n",
    "        rep2 = np.load(val_reps_folder + model_name + \".npy\")\n",
    "        # center and normalize\n",
    "        rep2 = rep2 - rep2.mean(axis=1, keepdims=True)\n",
    "        rep2 = rep2 / np.linalg.norm(rep2)\n",
    "        rep2 = rep2 * np.sqrt(rep2.shape[1])\n",
    "        reps_val[model_name] = rep2\n",
    "        \n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print('WARNING: IN ORDER TO RUN THIS CODE, THE IMAGENET REPRESENTATIONS MUST COMPUTED. SEE README.')\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict generalization, random y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_pred(y, lmbda, reps):\n",
    "    # ridge regression \n",
    "    # assume reps is dimension x number datapoints \n",
    "    rep_dim = reps.shape[0]\n",
    "    numpts = reps.shape[1]\n",
    "    \n",
    "    return np.linalg.solve((lmbda*np.eye(rep_dim) + (reps @ reps.T) / numpts), reps@y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_collected_correlations(lmbda, numtrials=50, numtrainsamples=10000):\n",
    "    collected_correlations = []\n",
    "\n",
    "    labels = []\n",
    "    for ky,val in distances.items():\n",
    "        if ky != 'predictor_dist_range':\n",
    "            labels.append(ky)\n",
    "#     print(labels)\n",
    "\n",
    "    def flatten_upper_right_triangle(curr_mat):\n",
    "        cv = []\n",
    "        assert(curr_mat.shape[0] == curr_mat.shape[1])\n",
    "        assert(curr_mat.shape[0] == len(model_names))\n",
    "        for i in range(len(model_names)-1):\n",
    "            for j in range(i+1,len(model_names)):\n",
    "                cv.append(curr_mat[i,j])\n",
    "        cv = np.asarray(cv)\n",
    "        return cv\n",
    "\n",
    "    dist_vecs = {}\n",
    "\n",
    "    for distname in labels:\n",
    "        dist_vecs[distname] = flatten_upper_right_triangle(distances[distname])\n",
    "\n",
    "    for tri in range(numtrials):\n",
    "        print(f'Trial {tri}')\n",
    "\n",
    "        y = np.random.randn(numtrainsamples,1) + 1\n",
    "\n",
    "        preds = {}\n",
    "        for model_name in model_names:\n",
    "    #         print(model_name)\n",
    "            preds[model_name] = find_best_pred(y, lmbda, reps_train[model_name][:,0:numtrainsamples])\n",
    "\n",
    "    #     # For each pair, compute the squared distance between predictions, averaged over test instances \n",
    "\n",
    "        errs = np.zeros((len(model_names), len(model_names)))\n",
    "        for ind1 in range(0, len(model_names)-1):\n",
    "            for ind2 in range(ind1+1, len(model_names)):\n",
    "                cp1 = preds[model_names[ind1]].T @ reps_val[model_names[ind1]]\n",
    "                cp2 = preds[model_names[ind2]].T @ reps_val[model_names[ind2]]\n",
    "    #             print(cp1.shape)\n",
    "                errs[ind1, ind2] = np.linalg.norm(cp1 - cp2)\n",
    "                errs[ind2, ind1] = errs[ind1, ind2]\n",
    "        err_vec = flatten_upper_right_triangle(errs)\n",
    "\n",
    "        correlations = []\n",
    "\n",
    "        for distname in labels:\n",
    "            val = scipy.stats.spearmanr(err_vec, dist_vecs[distname]).correlation\n",
    "            correlations.append(val)\n",
    "\n",
    "        collected_correlations.append(correlations)\n",
    "        \n",
    "    return labels, collected_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reps_train['alexnet_pretrained_rep'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names_dict = {'lin_cka_dist': 'CKA', 'mean_sq_cca_e2e' : 'CCA', 'pwcca_dist_e2e': 'PWCCA', 'procrustes': 'Procrustes'}\n",
    "\n",
    "label_names_dict['predictor_dist_0.0'] = 'GULP, $\\lambda = 0$'\n",
    "label_names_dict['predictor_dist_1e-07'] = 'GULP, $\\lambda = 10^{-7}$'\n",
    "label_names_dict['predictor_dist_1e-06'] = 'GULP, $\\lambda = 10^{-6}$'\n",
    "label_names_dict['predictor_dist_1e-05'] = 'GULP, $\\lambda = 10^{-5}$'\n",
    "label_names_dict['predictor_dist_0.0001'] = 'GULP, $\\lambda = 10^{-4}$'\n",
    "label_names_dict['predictor_dist_0.001'] = 'GULP, $\\lambda = 10^{-3}$'\n",
    "label_names_dict['predictor_dist_0.01'] = 'GULP, $\\lambda = 10^{-2}$'\n",
    "label_names_dict['predictor_dist_0.1'] = 'GULP, $\\lambda = 10^{-1}$'\n",
    "label_names_dict['predictor_dist_1.0'] = 'GULP, $\\lambda = 1$'\n",
    "label_names_dict['predictor_dist_10.0'] = 'GULP, $\\lambda = 10$'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0\n"
     ]
    }
   ],
   "source": [
    "# lmbda_vals = [0.001, 0.01, 0.1, 1]\n",
    "# lmbda_names = [\"10^{-3}\", \"10^{-2}\", \"10^{-1}\", \"1\"]\n",
    "lmbda_vals = [0.01, 0.1, 1]\n",
    "lmbda_names = [\"10^{-2}\", \"10^{-1}\", \"1\"]\n",
    "for lmbda_ind, lmbda in enumerate(lmbda_vals):\n",
    "    labels, collected_correlations = get_collected_correlations(lmbda, numtrials=10,numtrainsamples=5000)\n",
    "    \n",
    "    std_devs = []\n",
    "    means = []\n",
    "    for i in range(len(collected_correlations[0])):\n",
    "        cvs = [collected_correlations[j][i] for j in range(len(collected_correlations))]\n",
    "        std_devs.append(scipy.stats.sem(cvs))\n",
    "        means.append(np.mean(cvs))\n",
    "    std_devs = np.array(std_devs)\n",
    "    means = np.array(means)\n",
    "    \n",
    "    subset_labels = ['lin_cka_dist', 'pwcca_dist_e2e', 'procrustes', 'mean_sq_cca_e2e', 'predictor_dist_0.0', 'predictor_dist_1e-07', 'predictor_dist_1e-06', 'predictor_dist_1e-05', 'predictor_dist_0.0001', 'predictor_dist_0.001', 'predictor_dist_0.01', 'predictor_dist_0.1', 'predictor_dist_1.0', 'predictor_dist_10.0']\n",
    "    subset_label_names = [label_names_dict[x] for x in subset_labels]\n",
    "    subset_indices = []\n",
    "    for i in range(len(subset_labels)):\n",
    "        subset_indices.append(labels.index(subset_labels[i]))\n",
    "        \n",
    "    lbels = labels\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.bar(range(len(subset_labels)),means[subset_indices], yerr = std_devs[subset_indices])\n",
    "    plt.xticks(range(len(subset_labels)), labels=subset_label_names, rotation='vertical', fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.ylim(top=1)\n",
    "    plt.title(f'Spearman $\\\\rho$ with prediction distance for $\\\\lambda = {lmbda_names[lmbda_ind]}$', fontsize=16)\n",
    "    plt.savefig('../paper_figures/generalization_lambda' + str(lmbda) + '.pdf', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lmbda_vals = [0, 0.01]\n",
    "# lmbda_names = ['0', \"10^{-2}\"]\n",
    "# for lmbda_ind, lmbda in enumerate(lmbda_vals):\n",
    "#     labels, collected_correlations = get_collected_correlations(lmbda, numtrials=10,numtrainsamples=5000)\n",
    "    \n",
    "#     std_devs = []\n",
    "#     means = []\n",
    "#     for i in range(len(collected_correlations[0])):\n",
    "#         cvs = [collected_correlations[j][i] for j in range(len(collected_correlations))]\n",
    "#         std_devs.append(scipy.stats.sem(cvs))\n",
    "#         means.append(np.mean(cvs))\n",
    "#     std_devs = np.array(std_devs)\n",
    "#     means = np.array(means)\n",
    "# #     print(std_devs)\n",
    "#     subset_labels = ['lin_cka_dist', 'pwcca_dist_e2e', 'procrustes', 'mean_sq_cca_e2e', 'predictor_dist_0.0', 'predictor_dist_1e-06', 'predictor_dist_0.0001', 'predictor_dist_0.01', 'predictor_dist_1.0']\n",
    "#     subset_label_names = [label_names_dict[x] for x in subset_labels]\n",
    "#     subset_indices = []\n",
    "#     for i in range(len(subset_labels)):\n",
    "#         subset_indices.append(labels.index(subset_labels[i]))\n",
    "#     #     print(subset_indices)\n",
    "#     lbels = labels\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     fig = plt.figure()\n",
    "#     ax = fig.add_axes([0,0,1,1])\n",
    "#     ax.bar(range(len(subset_labels)),means[subset_indices], yerr = std_devs[subset_indices])\n",
    "#     plt.xticks(range(len(subset_labels)), labels=subset_label_names, rotation='vertical', fontsize=15)\n",
    "#     plt.yticks(fontsize=15)\n",
    "#     plt.ylim(top=1)\n",
    "#     plt.title(f'Spearman $\\\\rho$ with prediction distance for $\\\\lambda = {lmbda_names[lmbda_ind]}$', fontsize=16)\n",
    "#     plt.savefig('paper_figures/generalization_lambda' + str(lmbda) + '_condensed.pdf', bbox_inches='tight')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
