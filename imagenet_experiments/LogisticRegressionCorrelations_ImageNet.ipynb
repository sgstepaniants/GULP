{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.stats\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load distances and representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"distances/train/pretrained\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ImageNet distances between train datasets\n",
    "filenames = os.listdir(folder)\n",
    "distnames = []\n",
    "for filename in filenames:\n",
    "    if filename.endswith(\"npy\"):\n",
    "        distnames.append(filename[:-4])\n",
    "distnames = np.sort(distnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lin_cka_dist' 'lin_cka_prime_dist' 'mean_cca_e2e' 'mean_sq_cca_e2e'\n",
      " 'predictor_dist_0.0' 'predictor_dist_0.0001' 'predictor_dist_0.001'\n",
      " 'predictor_dist_0.01' 'predictor_dist_0.1' 'predictor_dist_1.0'\n",
      " 'predictor_dist_10.0' 'predictor_dist_100.0' 'predictor_dist_1000.0'\n",
      " 'predictor_dist_10000.0' 'predictor_dist_1e-05' 'predictor_dist_1e-06'\n",
      " 'predictor_dist_1e-07' 'predictor_dist_1e-08' 'predictor_dist_1e-09'\n",
      " 'predictor_dist_1e-10' 'predictor_dist_1e-11' 'predictor_dist_1e-12'\n",
      " 'predictor_dist_1e-13' 'predictor_dist_1e-14' 'predictor_dist_1e-15'\n",
      " 'predictor_dist_1e-16' 'predictor_dist_1e-17' 'predictor_dist_1e-18'\n",
      " 'predictor_dist_1e-19' 'predictor_dist_1e-20' 'procrustes'\n",
      " 'pwcca_dist_e2e']\n"
     ]
    }
   ],
   "source": [
    "print(distnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = np.load(f\"{folder}/stats.npz\")\n",
    "model_names = stats[\"model_names\"]\n",
    "total_models = len(model_names)\n",
    "dist_pairs_saved = stats[\"dist_pairs_saved\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Check all distance pairs are saved. The output should be all-zeros\n",
    "print(np.arange(total_models) - np.sum(dist_pairs_saved, axis=0))\n",
    "print(np.arange(total_models) - np.flip(np.sum(dist_pairs_saved, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alexnet_pretrained_rep' 'convnext_base_pretrained_rep'\n",
      " 'convnext_large_pretrained_rep' 'convnext_small_pretrained_rep'\n",
      " 'convnext_tiny_pretrained_rep' 'densenet_pretrained_rep'\n",
      " 'efficientnet_b0_pretrained_rep' 'efficientnet_b1_pretrained_rep'\n",
      " 'efficientnet_b2_pretrained_rep' 'efficientnet_b3_pretrained_rep'\n",
      " 'efficientnet_b4_pretrained_rep' 'efficientnet_b5_pretrained_rep'\n",
      " 'efficientnet_b6_pretrained_rep' 'efficientnet_b7_pretrained_rep'\n",
      " 'googlenet_pretrained_rep' 'inception_pretrained_rep'\n",
      " 'mnasnet_pretrained_rep' 'mobilenet_v2_pretrained_rep'\n",
      " 'mobilenet_v3_large_pretrained_rep' 'mobilenet_v3_small_pretrained_rep'\n",
      " 'regnet_x_16gf_pretrained_rep' 'regnet_x_1_6gf_pretrained_rep'\n",
      " 'regnet_x_32gf_pretrained_rep' 'regnet_x_3_2gf_pretrained_rep'\n",
      " 'regnet_x_400mf_pretrained_rep' 'regnet_x_800mf_pretrained_rep'\n",
      " 'regnet_x_8gf_pretrained_rep' 'regnet_y_16gf_pretrained_rep'\n",
      " 'regnet_y_1_6gf_pretrained_rep' 'regnet_y_32gf_pretrained_rep'\n",
      " 'regnet_y_3_2gf_pretrained_rep' 'regnet_y_400mf_pretrained_rep'\n",
      " 'regnet_y_800mf_pretrained_rep' 'regnet_y_8gf_pretrained_rep'\n",
      " 'resnet18_pretrained_rep' 'resnext50_32x4d_pretrained_rep'\n",
      " 'shufflenet_pretrained_rep' 'squeezenet_pretrained_rep'\n",
      " 'vgg16_pretrained_rep' 'vit_b_16_pretrained_rep'\n",
      " 'vit_b_32_pretrained_rep' 'vit_l_16_pretrained_rep'\n",
      " 'vit_l_32_pretrained_rep' 'wide_resnet50_2_pretrained_rep']\n"
     ]
    }
   ],
   "source": [
    "print(model_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_cka_dist\n",
      "lin_cka_prime_dist\n",
      "mean_cca_e2e\n",
      "mean_sq_cca_e2e\n",
      "predictor_dist_0.0\n",
      "predictor_dist_0.0001\n",
      "predictor_dist_0.001\n",
      "predictor_dist_0.01\n",
      "predictor_dist_0.1\n",
      "predictor_dist_1.0\n",
      "predictor_dist_10.0\n",
      "predictor_dist_100.0\n",
      "predictor_dist_1000.0\n",
      "predictor_dist_10000.0\n",
      "predictor_dist_1e-05\n",
      "predictor_dist_1e-06\n",
      "predictor_dist_1e-07\n",
      "predictor_dist_1e-08\n",
      "predictor_dist_1e-09\n",
      "predictor_dist_1e-10\n",
      "predictor_dist_1e-11\n",
      "predictor_dist_1e-12\n",
      "predictor_dist_1e-13\n",
      "predictor_dist_1e-14\n",
      "predictor_dist_1e-15\n",
      "predictor_dist_1e-16\n",
      "predictor_dist_1e-17\n",
      "predictor_dist_1e-18\n",
      "predictor_dist_1e-19\n",
      "predictor_dist_1e-20\n",
      "procrustes\n",
      "pwcca_dist_e2e\n"
     ]
    }
   ],
   "source": [
    "distances = {}\n",
    "def symmetrize(A):\n",
    "    n = A.shape[0]\n",
    "    B = A.copy()\n",
    "    B[np.tril_indices(n)] = B.T[np.tril_indices(n)]\n",
    "    return B\n",
    "for distname in distnames:\n",
    "    print(distname)\n",
    "    curr_dist = np.load(f\"{folder}/{distname}.npy\")  \n",
    "    distances[distname] = symmetrize(curr_dist)\n",
    "#     print(distances[distname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alexnet_pretrained_rep\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'reps/train/10000_eval/alexnet_pretrained_rep.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pw/wkdn0vxs0b54swhpwjg6s0x00000gn/T/ipykernel_16572/3500416425.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mrep1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_reps_folder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m# center and normalize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mrep1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrep1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrep1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'reps/train/10000_eval/alexnet_pretrained_rep.npy'"
     ]
    }
   ],
   "source": [
    "train_reps_folder = 'reps/train/10000_eval/'\n",
    "val_reps_folder = 'reps/val/3000_eval/'\n",
    "\n",
    "# Load ImageNet representations\n",
    "reps_train = {}\n",
    "reps_val = {}\n",
    "for model_name in model_names:\n",
    "    print(model_name)\n",
    "    rep1 = np.load(train_reps_folder + model_name + \".npy\")\n",
    "    # center and normalize\n",
    "    rep1 = rep1 - rep1.mean(axis=1, keepdims=True)\n",
    "    rep1 = rep1 / np.linalg.norm(rep1)\n",
    "    rep1 = rep1 * np.sqrt(rep1.shape[1])\n",
    "    reps_train[model_name] = rep1\n",
    "    \n",
    "    rep2 = np.load(val_reps_folder + model_name + \".npy\")\n",
    "    # center and normalize\n",
    "    rep2 = rep2 - rep2.mean(axis=1, keepdims=True)\n",
    "    rep2 = rep2 / np.linalg.norm(rep2)\n",
    "    rep2 = rep2 * np.sqrt(rep2.shape[1])\n",
    "    reps_val[model_name] = rep2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict generalization, random y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_pred(y, lmbda, reps, logistic=False):\n",
    "    # ridge regression \n",
    "    # assume reps is dimension x number datapoints \n",
    "\n",
    "    rep_dim = reps.shape[0]\n",
    "    numpts = reps.shape[1]\n",
    "    \n",
    "    if logistic is False:\n",
    "        return np.linalg.solve((lmbda*np.eye(rep_dim) + (reps @ reps.T) / numpts), reps@y)\n",
    "    else:     \n",
    "        clf = LogisticRegression(random_state=0).fit(reps.T, y)\n",
    "        return clf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_collected_correlations(lmbda, numtrials=50, numtrainsamples=10000):\n",
    "    collected_correlations = []\n",
    "\n",
    "    labels = []\n",
    "    for ky,val in distances.items():\n",
    "        if ky != 'predictor_dist_range':\n",
    "            labels.append(ky)\n",
    "\n",
    "    def flatten_upper_right_triangle(curr_mat):\n",
    "        cv = []\n",
    "        assert(curr_mat.shape[0] == curr_mat.shape[1])\n",
    "        assert(curr_mat.shape[0] == len(model_names))\n",
    "        for i in range(len(model_names)-1):\n",
    "            for j in range(i+1,len(model_names)):\n",
    "                cv.append(curr_mat[i,j])\n",
    "        cv = np.asarray(cv)\n",
    "        return cv\n",
    "\n",
    "    dist_vecs = {}\n",
    "\n",
    "    for distname in labels:\n",
    "        dist_vecs[distname] = flatten_upper_right_triangle(distances[distname])\n",
    "\n",
    "    numclasses = 1\n",
    "    log_reg = True\n",
    "    for tri in range(numtrials):\n",
    "        print(f'Trial {tri}')\n",
    "\n",
    "        y = np.random.randn(numtrainsamples,numclasses) \n",
    "        if log_reg:\n",
    "            y = y[:, 0]\n",
    "            y = (y > 0) \n",
    "        else:\n",
    "            log_reg += 1\n",
    "\n",
    "        preds = {}\n",
    "        count=0\n",
    "        for model_name in model_names:\n",
    "    #         print(model_name)\n",
    "            preds[model_name] = find_best_pred(y, lmbda, reps_train[model_name][:,0:numtrainsamples], logistic=log_reg)\n",
    "            if tri==0 and count==0 and not log_reg:\n",
    "                print('shape of prediction', preds[model_name].shape)\n",
    "                count+=1\n",
    "\n",
    "    #     # For each pair, compute the squared distance between predictions, averaged over test instances \n",
    "\n",
    "        errs = np.zeros((len(model_names), len(model_names)))\n",
    "        for ind1 in range(0, len(model_names)-1):\n",
    "            for ind2 in range(ind1+1, len(model_names)):\n",
    "                if not log_reg:\n",
    "                    cp1 = preds[model_names[ind1]].T @ reps_val[model_names[ind1]]\n",
    "                    cp2 = preds[model_names[ind2]].T @ reps_val[model_names[ind2]]\n",
    "                else:\n",
    "                    cp1 = preds[model_name].predict(reps_val[model_names[ind1]].T)\n",
    "                    cp2 = preds[model_name].predict(reps_val[model_names[ind2]].T)\n",
    "                if log_reg:\n",
    "                    errs[ind1, ind2] = (cp1 != cp2).sum()\n",
    "                else:\n",
    "                    errs[ind1, ind2] = np.linalg.norm(cp1 - cp2)\n",
    "                errs[ind2, ind1] = errs[ind1, ind2]\n",
    "        err_vec = flatten_upper_right_triangle(errs)\n",
    "\n",
    "        correlations = []\n",
    "\n",
    "        for distname in labels:\n",
    "            val = scipy.stats.spearmanr(err_vec, dist_vecs[distname]).correlation\n",
    "            correlations.append(val)\n",
    "\n",
    "        collected_correlations.append(correlations)\n",
    "        \n",
    "    return labels, collected_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names_dict = {'lin_cka_dist': 'CKA', 'mean_sq_cca_e2e' : 'CCA', 'pwcca_dist_e2e': 'PWCCA', 'procrustes': 'Procrustes'}\n",
    "\n",
    "label_names_dict['predictor_dist_0.0'] = 'GULP, $\\lambda = 0$'\n",
    "label_names_dict['predictor_dist_1e-07'] = 'GULP, $\\lambda = 10^{-7}$'\n",
    "label_names_dict['predictor_dist_1e-06'] = 'GULP, $\\lambda = 10^{-6}$'\n",
    "label_names_dict['predictor_dist_1e-05'] = 'GULP, $\\lambda = 10^{-5}$'\n",
    "label_names_dict['predictor_dist_0.0001'] = 'GULP, $\\lambda = 10^{-4}$'\n",
    "label_names_dict['predictor_dist_0.001'] = 'GULP, $\\lambda = 10^{-3}$'\n",
    "label_names_dict['predictor_dist_0.01'] = 'GULP, $\\lambda = 10^{-2}$'\n",
    "label_names_dict['predictor_dist_0.1'] = 'GULP, $\\lambda = 10^{-1}$'\n",
    "label_names_dict['predictor_dist_1.0'] = 'GULP, $\\lambda = 1$'\n",
    "label_names_dict['predictor_dist_10.0'] = 'GULP, $\\lambda = 10$'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute correlations over several trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_collected_correlations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pw/wkdn0vxs0b54swhpwjg6s0x00000gn/T/ipykernel_16572/3723941471.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlmbda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollected_correlations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_collected_correlations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumtrainsamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstd_devs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_collected_correlations' is not defined"
     ]
    }
   ],
   "source": [
    "lmbda_vals = [0] #, 0.001, 0.01, 0.1, 1, 10]\n",
    "lmbda_names = ['0'] #, \"10^{-3}\", \"10^{-2}\", \"10^{-1}\", \"1\", \"10\"]\n",
    "# Lambda does not matter for logistic regression\n",
    "\n",
    "lmbda = 0\n",
    "labels, collected_correlations = get_collected_correlations(lmbda, numtrials=10,numtrainsamples=5000)\n",
    "\n",
    "std_devs = []\n",
    "means = []\n",
    "for i in range(len(collected_correlations[0])):\n",
    "    cvs = [collected_correlations[j][i] for j in range(len(collected_correlations))]\n",
    "    std_devs.append(scipy.stats.sem(cvs))\n",
    "    means.append(np.mean(cvs))\n",
    "std_devs = np.array(std_devs)\n",
    "means = np.array(means)\n",
    "subset_labels = ['lin_cka_dist', 'pwcca_dist_e2e', 'procrustes', 'mean_sq_cca_e2e', \\\n",
    "                 'predictor_dist_0.0', 'predictor_dist_1e-07', 'predictor_dist_1e-06',\\\n",
    "                 'predictor_dist_1e-05', 'predictor_dist_0.0001', 'predictor_dist_0.001', \\\n",
    "                 'predictor_dist_0.01', 'predictor_dist_0.1', 'predictor_dist_1.0', 'predictor_dist_10.0']\n",
    "subset_label_names = [label_names_dict[x] for x in subset_labels]\n",
    "subset_indices = []\n",
    "for i in range(len(subset_labels)):\n",
    "    subset_indices.append(labels.index(subset_labels[i]))\n",
    "lbels = labels\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,1,1])\n",
    "\n",
    "ax.bar(range(len(subset_labels)),means[subset_indices], yerr = std_devs[subset_indices])\n",
    "plt.xticks(range(len(subset_labels)), labels=subset_label_names, rotation='vertical', fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.ylim(top=1)\n",
    "plt.title(f'Spearman $\\\\rho$ with prediction distance', fontsize=16)\n",
    "#plt.savefig('paper_figures/logistic_generalization.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e70badacbf542457a1b8611e7c89f41d1aae0b4a8ef8cfc10165f457ce5020f"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
